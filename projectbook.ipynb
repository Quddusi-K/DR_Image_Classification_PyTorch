{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2822650,"sourceType":"datasetVersion","datasetId":1715304},{"sourceId":9507295,"sourceType":"datasetVersion","datasetId":5786672},{"sourceId":9507425,"sourceType":"datasetVersion","datasetId":5786772},{"sourceId":9507778,"sourceType":"datasetVersion","datasetId":5787029}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/quddusikashaf/projectbook?scriptVersionId=200411941\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Function to Load data from Multiple Datasets","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nclass MultiDatasetLoader(Dataset):\n    def __init__(self, dataset_info_list, transform=None, num_samples=500):\n        \"\"\"\n        Initializes the dataset loader for multiple datasets with varying configurations.\n\n        :param dataset_info_list: A list where each item is a list containing:\n                                  [image_dir, csv_file, image_column, label_column, binary (True/False)]\n        :param transform: Transformations to be applied to the images.\n        :param num_samples: Number of samples to load from each dataset.\n        \"\"\"\n        self.transform = transform\n        self.data = pd.DataFrame()  # Create an empty DataFrame to hold data from all datasets\n\n        # Process each dataset in the dataset_info_list\n        for dataset_info in dataset_info_list:\n            image_dir, csv_file = dataset_info[:2]\n            image_column = dataset_info[2] if len(dataset_info) > 2 else \"name\"\n            label_column = dataset_info[3] if len(dataset_info) > 3 else \"diagnosis\"\n            is_binary = dataset_info[4] if len(dataset_info) > 4 else True\n            self.ext = dataset_info[5] if len(dataset_info) > 5 else ''\n\n            # Load CSV file\n#             data_part = pd.read_csv(csv_file)\n            data_part = pd.read_csv(csv_file, dtype={image_column: str})\n\n            # Convert labels to binary if needed\n            if not is_binary:\n                data_part['binary_label'] = data_part[label_column].apply(lambda x: 0 if x == 0 or x == 1 else 1)\n                label_column = 'binary_label'  # Use the binary label for further processing\n            else:\n                data_part['binary_label'] = data_part[label_column]\n\n            # Sample images from both classes equally\n            class_0_count = len(data_part[data_part['binary_label'] == 0])\n            class_1_count = len(data_part[data_part['binary_label'] == 1])\n            min_samples_0 = min(class_0_count, num_samples)\n            min_samples_1 = min(class_1_count, num_samples)\n            print(f'Class 0: {min_samples_0}, Class 1: {min_samples_1}')\n            # Sample data from each class\n            data_0 = data_part[data_part['binary_label'] == 0].sample(n=min_samples_0, random_state=42)\n            data_1 = data_part[data_part['binary_label'] == 1].sample(n=min_samples_1, random_state=42)\n\n            # Concatenate and store dataset info\n            data_part_sampled = pd.concat([data_0, data_1], axis=0)\n            data_part_sampled['image_dir'] = image_dir  # Store the directory for the images\n\n            # Append to the full dataset\n            self.data = pd.concat([self.data, data_part_sampled], axis=0)\n\n        # Shuffle the dataset\n        self.data = self.data.sample(frac=1).reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Get the image name, handle cases with or without extension\n        img_name = self.data.iloc[idx]['name']\n        image_dir = self.data.iloc[idx]['image_dir']\n\n        # If the image name doesn't contain an extension, add one (e.g., '.png')\n#         if not any(ext in img_name for ext in ['.png', '.jpg','jpeg']):\n#             img_name = f\"{img_name}.png\"  # Default to .png, modify as per the image format you expect\n\n        img_path = os.path.join(image_dir, img_name)\n\n        try:\n            # Open the image and convert it to RGB\n            image = Image.open(img_path)\n        except Exception as e:\n            print(f\"Error loading image: {img_path}. Skipping to next image.\")\n            return self.__getitem__((idx + 1) % len(self.data))  # Skip to next image if an error occurs\n\n        # Get the label for the image\n        label = self.data.iloc[idx]['binary_label']\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T03:37:58.13321Z","iopub.execute_input":"2024-10-11T03:37:58.133614Z","iopub.status.idle":"2024-10-11T03:38:01.969006Z","shell.execute_reply.started":"2024-10-11T03:37:58.133574Z","shell.execute_reply":"2024-10-11T03:38:01.967765Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"eyepacs_train=['/kaggle/input/eyepacs-ai4med/EyePACS/train','/kaggle/input/eyepacs-ai4med/EyePACS/train.csv']\neyepacs_test=['/kaggle/input/eyepacs-ai4med/EyePACS/test','/kaggle/input/eyepacs-ai4med/EyePACS/test.csv']\neyepacs_valid=['/kaggle/input/eyepacs-ai4med/EyePACS/valid','/kaggle/input/eyepacs-ai4med/EyePACS/valid.csv']\n\nidrid_train=['/kaggle/input/idrid-ai4med/idrid/train','/kaggle/input/idrid-ai4med/idrid/train.csv']\nidrid_test=['/kaggle/input/idrid-ai4med/idrid/test','/kaggle/input/idrid-ai4med/idrid/test.csv']\nidrid_valid=['/kaggle/input/idrid-ai4med/idrid/valid','/kaggle/input/idrid-ai4med/idrid/valid.csv']\n\nmessidor_train=['/kaggle/input/messidor-ai4med/train','/kaggle/input/messidor-ai4med/train.csv']\nmessidor_test=['/kaggle/input/messidor-ai4med/test','/kaggle/input/messidor-ai4med/test.csv']\nmessidor_valid=['/kaggle/input/messidor-ai4med/valid','/kaggle/input/messidor-ai4med/valid.csv']\n\naptos_train=['/kaggle/input/aptos-ai4med/train_images','/kaggle/input/aptos-ai4med/trainc.csv']\naptos_test=['/kaggle/input/aptos-ai4med/test_images','/kaggle/input/aptos-ai4med/testc.csv']\naptos_valid=['/kaggle/input/aptos-ai4med/val_images','/kaggle/input/aptos-ai4med/validc.csv']\n\n\nhybrid_train=[eyepacs_train,idrid_train,messidor_train,aptos_train]\nhybrid_test=[eyepacs_test,idrid_test,messidor_test,aptos_test]\nhybrid_valid=[eyepacs_valid,idrid_valid,messidor_valid, aptos_valid]","metadata":{"execution":{"iopub.status.busy":"2024-10-11T03:38:01.970948Z","iopub.execute_input":"2024-10-11T03:38:01.971467Z","iopub.status.idle":"2024-10-11T03:38:01.978846Z","shell.execute_reply.started":"2024-10-11T03:38:01.971416Z","shell.execute_reply":"2024-10-11T03:38:01.977788Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Train, Test and Validate Function","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nimport numpy as np\n\n# Training function\ndef train_model(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in tqdm(dataloader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Validation function\ndef validate_model(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Testing function\ndef test_model(model, dataloader, device):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n    \n    return accuracy_score(all_labels, all_preds)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T03:38:01.980565Z","iopub.execute_input":"2024-10-11T03:38:01.981189Z","iopub.status.idle":"2024-10-11T03:38:04.861895Z","shell.execute_reply.started":"2024-10-11T03:38:01.981132Z","shell.execute_reply":"2024-10-11T03:38:04.86032Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Inception V3","metadata":{}},{"cell_type":"markdown","source":"Early Stopping and Learning Scheduler has been used here. It has three different functions for Training, Validating and Testing.","metadata":{}},{"cell_type":"code","source":"from torchvision.models import Inception_V3_Weights  \n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nimport numpy as np\n\n\n# Define image transformations\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\n# Parameters\nbatch_size = 32\nlearning_rate = 1e-4\n\n\n# Prepare dataset\n# train_image_dir = '/kaggle/input/hybrid-fundus-dataset/Train'\n# train_csv_file = '/kaggle/input/hybrid-fundus-dataset/train.csv'\n# train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=transform)\n\n# test_image_dir = '/kaggle/input/hybrid-fundus-dataset/Test'\n# test_csv_file = '/kaggle/input/hybrid-fundus-dataset/test.csv'\n# test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=transform,num_samples=100,nameColumn=\"Name\")\n\n# valid_image_dir = '/kaggle/input/hybrid-fundus-dataset/Valid'\n# valid_csv_file = '/kaggle/input/hybrid-fundus-dataset/valid.csv'\n# valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=transform,num_samples=100)\n\n\n# Create dataset instance\ntrain_dataset = MultiDatasetLoader(hybrid_train, transform=transform, num_samples=1000)\ntest_dataset = MultiDatasetLoader(hybrid_test, transform=transform, num_samples=1000)\nvalid_dataset = MultiDatasetLoader(hybrid_valid, transform=transform, num_samples=1000)\n\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# Load pre-trained InceptionV3 model\nmodel = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\nmodel.aux_logits = False\nmodel.fc = nn.Linear(model.fc.in_features, 2)\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T03:38:04.865087Z","iopub.execute_input":"2024-10-11T03:38:04.865852Z","iopub.status.idle":"2024-10-11T03:38:06.481012Z","shell.execute_reply.started":"2024-10-11T03:38:04.865773Z","shell.execute_reply":"2024-10-11T03:38:06.47947Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Class 0: 1000, Class 1: 1000\nClass 0: 600, Class 1: 600\nClass 0: 172, Class 1: 361\nClass 0: 1000, Class 1: 1000\nClass 0: 300, Class 1: 300\nClass 0: 305, Class 1: 302\nClass 0: 0, Class 1: 203\nClass 0: 229, Class 1: 137\nClass 0: 600, Class 1: 600\nClass 0: 300, Class 1: 300\nClass 0: 13, Class 1: 250\nClass 0: 212, Class 1: 154\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n100%|██████████| 104M/104M [00:00<00:00, 151MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 10\nbest_val_loss=np.inf\npatience=3\npatience_counter=0\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n\n# Training loop with early stopping\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n    scheduler.step()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n\n    # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Test the model\ntest_acc = test_model(model, test_loader, device)\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T03:38:06.482303Z","iopub.execute_input":"2024-10-11T03:38:06.482834Z","iopub.status.idle":"2024-10-11T04:02:37.183647Z","shell.execute_reply.started":"2024-10-11T03:38:06.482724Z","shell.execute_reply":"2024-10-11T04:02:37.181247Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Training:  51%|█████     | 92/180 [24:29<23:25, 15.98s/it] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Training loop with early stopping\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 12\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate_model(model, val_loader, criterion, device)\n\u001b[1;32m     14\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n","Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## ResNet 50","metadata":{}},{"cell_type":"code","source":"from torchvision.models import ResNet50_Weights\nfrom torchvision.transforms import InterpolationMode\n\n# Define data transformations using ResNet18 inference transforms\nrestnet_preprocess = transforms.Compose([\n    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),  # Resizing to 256\n    transforms.CenterCrop(224),                                        # Central crop of 224\n    transforms.ToTensor(),                                             \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n])\nbatch_size=32\n# Prepare datasets\n# resnet_train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=restnet_preprocess)\n# resnet_test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=restnet_preprocess, num_samples=300,nameColumn=\"Name\")\n# resnet_valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=restnet_preprocess, num_samples=300)\nresnet_train_dataset = MultiDatasetLoader(hybrid_train, transform=restnet_preprocess, num_samples=1000)\nresnet_test_dataset = MultiDatasetLoader(hybrid_test, transform=restnet_preprocess, num_samples=1000)\nresnet_valid_dataset = MultiDatasetLoader(hybrid_valid, transform=restnet_preprocess, num_samples=1000)\n\n\n\n# Data loaders\nresnet_train_loader = DataLoader(resnet_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nresnet_val_loader = DataLoader(resnet_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\nresnet_test_loader = DataLoader(resnet_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n\nresnet_model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\nresnet_model.fc = nn.Linear(resnet_model.fc.in_features, 2)  # Adjust the final layer for binary classification\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nresnet_model.to(device)\nprint('')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T04:02:37.185213Z","iopub.status.idle":"2024-10-11T04:02:37.18593Z","shell.execute_reply.started":"2024-10-11T04:02:37.185567Z","shell.execute_reply":"2024-10-11T04:02:37.185603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define loss, optimizer, and learning rate scheduler\nresnet_criterion = nn.CrossEntropyLoss()\nresnet_optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\nresnet_scheduler = optim.lr_scheduler.StepLR(resnet_optimizer, step_size=5, gamma=0.1)\n\n# Early stopping setup\nbest_val_loss = float('inf')\npatience_counter = 0\npatience=3\nnum_epochs=10\n# Training loop with early stopping\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_model(resnet_model, resnet_train_loader, resnet_criterion, resnet_optimizer, device)\n    val_loss, val_acc = validate_model(resnet_model, resnet_val_loader, resnet_criterion, device)\n    resnet_scheduler.step()\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n    \n    # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Test the model\ntest_acc = test_model(resnet_model, resnet_test_loader, device)\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T04:02:37.188539Z","iopub.status.idle":"2024-10-11T04:02:37.189207Z","shell.execute_reply.started":"2024-10-11T04:02:37.188888Z","shell.execute_reply":"2024-10-11T04:02:37.18892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EfficientNet-B4","metadata":{}},{"cell_type":"code","source":"import torch\n# import torch_xla.core.xla_model as xm\nfrom torchvision.models import EfficientNet_B4_Weights\nfrom torchvision.transforms import InterpolationMode\n# Define EfficientNet-B7 inference preprocessing transforms\nefficientnet_preprocess = transforms.Compose([\n    transforms.Resize(384, interpolation=InterpolationMode.BICUBIC),  # Resize to 600 using BICUBIC interpolation\n    transforms.CenterCrop(380),                                        # Central crop of 600\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n])\n# train_image_dir = '/kaggle/input/aptos2019/train_images/train_images'\n# train_csv_file = '/kaggle/input/aptos2019/train_1.csv'\n# test_image_dir = '/kaggle/input/aptos2019/test_images/test_images'\n# test_csv_file = '/kaggle/input/aptos2019/test.csv'\n# valid_image_dir = '/kaggle/input/aptos2019/val_images/val_images'\n# valid_csv_file = '/kaggle/input/aptos2019/valid.csv'\n\n\n# Prepare datasets\n# efficientnet_train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=efficientnet_preprocess,num_samples=550)\n# efficientnet_valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=efficientnet_preprocess, num_samples=200)\n# efficientnet_test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=efficientnet_preprocess, num_samples=200,nameColumn=\"Name\")\nefficientnet_train_dataset = MultiDatasetLoader(hybrid_train, transform = efficientnet_preprocess, num_samples=1000)\nefficientnet_test_dataset = MultiDatasetLoader(hybrid_test, transform = efficientnet_preprocess, num_samples=1000)\nefficientnet_valid_dataset = MultiDatasetLoader(hybrid_valid, transform = efficientnet_preprocess, num_samples=1000)\n\n\n# Data loaders\nefficientnet_train_loader = DataLoader(efficientnet_train_dataset, batch_size=16, shuffle=True, num_workers=4)\nefficientnet_val_loader = DataLoader(efficientnet_valid_dataset, batch_size=16, shuffle=False, num_workers=4)\nefficientnet_test_loader = DataLoader(efficientnet_test_dataset, batch_size=16, shuffle=False, num_workers=4)\n\n# Initialize the EfficientNet-B7 model\n\nefficientnet_model = models.efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1)\nefficientnet_model.classifier[1] = nn.Linear(efficientnet_model.classifier[1].in_features, 2)  # Adjust final layer for binary classification\nefficientnet_model.to(device)\n\n# Define the loss, optimizer, and learning rate scheduler\nefficientnet_criterion = nn.CrossEntropyLoss()\nefficientnet_optimizer = optim.Adam(efficientnet_model.parameters(), lr=0.001)\nefficientnet_scheduler = optim.lr_scheduler.CosineAnnealingLR(efficientnet_optimizer, T_max=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T04:02:37.191946Z","iopub.status.idle":"2024-10-11T04:02:37.192416Z","shell.execute_reply.started":"2024-10-11T04:02:37.192203Z","shell.execute_reply":"2024-10-11T04:02:37.192225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Early stopping setup\nbest_val_loss_efficientnet = float('inf')\npatience=3\n# Training loop for EfficientNet-B7 with early stopping\nnum_epoch=10\npatience_counter_efficientnet=0\nprint(\"Training EfficientNet-B7...\")\nfor epoch in range(num_epoch):\n    train_loss_efficientnet, train_acc_efficientnet = train_model(efficientnet_model, efficientnet_train_loader, efficientnet_criterion, efficientnet_optimizer, device)\n    val_loss_efficientnet, val_acc_efficientnet = validate_model(efficientnet_model, efficientnet_val_loader, efficientnet_criterion, device)\n    efficientnet_scheduler.step()\n\n    print(f\"EfficientNet-B7 Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss_efficientnet:.4f}, Train Accuracy: {train_acc_efficientnet:.4f}\")\n    print(f\"Validation Loss: {val_loss_efficientnet:.4f}, Validation Accuracy: {val_acc_efficientnet:.4f}\")\n\n    # Early stopping check\n    if val_loss_efficientnet < best_val_loss_efficientnet:\n        best_val_loss_efficientnet = val_loss_efficientnet\n        patience_counter_efficientnet = 0\n    else:\n        patience_counter_efficientnet += 1\n        if patience_counter_efficientnet >= patience:\n            print(\"Early stopping for EfficientNet-B7 triggered\")\n            break\n\n# Test the EfficientNet-B7 model\ntest_acc_efficientnet = test_model(efficientnet_model, efficientnet_test_loader, device)\nprint(f\"EfficientNet-B4 Test Accuracy: {test_acc_efficientnet:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T04:02:37.194703Z","iopub.status.idle":"2024-10-11T04:02:37.195913Z","shell.execute_reply.started":"2024-10-11T04:02:37.195536Z","shell.execute_reply":"2024-10-11T04:02:37.195572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ViT","metadata":{}},{"cell_type":"code","source":"from torchvision.models import ViT_B_32_Weights\nfrom torchvision import models, transforms\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n# Define data transformations using Vision Transformer inference transforms\nvit_preprocess = transforms.Compose([\n    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),  # Resize to 256\n    transforms.CenterCrop(224),                                        # Central crop of 224\n    transforms.ToTensor(),                                             \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n])\nbatch_size=32\n\n# Prepare datasets\n# vit_train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=vit_preprocess)\n# vit_test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=vit_preprocess, num_samples=100,nameColumn=\"Name\")\n# vit_valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=vit_preprocess, num_samples=100)\nvit_train_dataset = MultiDatasetLoader(hybrid_train, transform = vit_preprocess, num_samples=1000)\nvit_test_dataset = MultiDatasetLoader(hybrid_test, transform = vit_preprocess, num_samples=1000)\nvit_valid_dataset = MultiDatasetLoader(hybrid_valid, transform = vit_preprocess, num_samples=1000)\n\n# Data loaders\nvit_train_loader = DataLoader(vit_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nvit_val_loader = DataLoader(vit_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\nvit_test_loader = DataLoader(vit_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# Load pre-trained Vision Transformer (ViT-B/16) model\nvit_model = models.vit_b_32(weights=ViT_B_32_Weights.IMAGENET1K_V1)\nvit_model.heads.head = nn.Linear(vit_model.heads.head.in_features, 2)  # Adjust the final layer for binary classification\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T04:02:37.1981Z","iopub.status.idle":"2024-10-11T04:02:37.198767Z","shell.execute_reply.started":"2024-10-11T04:02:37.198422Z","shell.execute_reply":"2024-10-11T04:02:37.198454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvit_model.to(device)\n\n# Define loss, optimizer, and learning rate scheduler\nvit_criterion = nn.CrossEntropyLoss()\nvit_optimizer = optim.AdamW(vit_model.parameters(), lr=0.00005)\nvit_scheduler = optim.lr_scheduler.StepLR(vit_optimizer, step_size=5, gamma=0.1)\n\n# Early stopping setup\nbest_val_loss = float('inf')\npatience_counter = 0\npatience = 3\nnum_epochs = 20\n\n# Training loop with early stopping\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_model(vit_model, vit_train_loader, vit_criterion, vit_optimizer, device)\n    val_loss, val_acc = validate_model(vit_model, vit_val_loader, vit_criterion, device)\n    vit_scheduler.step()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n\n#     # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Test the model\ntest_acc = test_model(vit_model, vit_test_loader, device)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T04:02:37.200909Z","iopub.status.idle":"2024-10-11T04:02:37.201536Z","shell.execute_reply.started":"2024-10-11T04:02:37.20122Z","shell.execute_reply":"2024-10-11T04:02:37.201252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Appendix\n","metadata":{}},{"cell_type":"code","source":"# Parameters\nimage_dir = '/kaggle/input/hybrid-fundus-dataset/Test'\ncsv_file = '/kaggle/input/hybrid-fundus-dataset/test.csv'\nn = 500  # Number of images per class\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Create dataset and dataloader\ndataset = BinaryClassificationDataset(image_dir=image_dir, csv_file=csv_file, transform=transform,nameColumn=\"Name\")\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n\n# Example usage: Iterating through the DataLoader\nfor images, labels in dataloader:\n    print(images.shape, labels.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:46:07.222204Z","iopub.status.idle":"2024-09-24T14:46:07.222677Z","shell.execute_reply.started":"2024-09-24T14:46:07.222458Z","shell.execute_reply":"2024-09-24T14:46:07.222492Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}