{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2822650,"sourceType":"datasetVersion","datasetId":1715304},{"sourceId":9507295,"sourceType":"datasetVersion","datasetId":5786672},{"sourceId":9507425,"sourceType":"datasetVersion","datasetId":5786772},{"sourceId":9507778,"sourceType":"datasetVersion","datasetId":5787029}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/quddusikashaf/projectbook?scriptVersionId=200275060\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Function to Load data from Multiple Datasets","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nclass MultiDatasetLoader(Dataset):\n    def __init__(self, dataset_info_list, transform=None, num_samples=500):\n        \"\"\"\n        Initializes the dataset loader for multiple datasets with varying configurations.\n\n        :param dataset_info_list: A list where each item is a list containing:\n                                  [image_dir, csv_file, image_column, label_column, binary (True/False)]\n        :param transform: Transformations to be applied to the images.\n        :param num_samples: Number of samples to load from each dataset.\n        \"\"\"\n        self.transform = transform\n        self.data = pd.DataFrame()  # Create an empty DataFrame to hold data from all datasets\n\n        # Process each dataset in the dataset_info_list\n        for dataset_info in dataset_info_list:\n            image_dir, csv_file = dataset_info[:2]\n            image_column = dataset_info[2] if len(dataset_info) > 2 else \"name\"\n            label_column = dataset_info[3] if len(dataset_info) > 3 else \"diagnosis\"\n            is_binary = dataset_info[4] if len(dataset_info) > 4 else True\n            self.ext = dataset_info[5] if len(dataset_info) > 5 else ''\n\n            # Load CSV file\n#             data_part = pd.read_csv(csv_file)\n            data_part = pd.read_csv(csv_file, dtype={image_column: str})\n\n            # Convert labels to binary if needed\n            if not is_binary:\n                data_part['binary_label'] = data_part[label_column].apply(lambda x: 0 if x == 0 or x == 1 else 1)\n                label_column = 'binary_label'  # Use the binary label for further processing\n            else:\n                data_part['binary_label'] = data_part[label_column]\n\n            # Sample images from both classes equally\n            class_0_count = len(data_part[data_part['binary_label'] == 0])\n            class_1_count = len(data_part[data_part['binary_label'] == 1])\n            min_samples_0 = min(class_0_count, num_samples)\n            min_samples_1 = min(class_1_count, num_samples)\n            print(f'Class 0: {min_samples_0}, Class 1: {min_samples_1}')\n            # Sample data from each class\n            data_0 = data_part[data_part['binary_label'] == 0].sample(n=min_samples_0, random_state=42)\n            data_1 = data_part[data_part['binary_label'] == 1].sample(n=min_samples_1, random_state=42)\n\n            # Concatenate and store dataset info\n            data_part_sampled = pd.concat([data_0, data_1], axis=0)\n            data_part_sampled['image_dir'] = image_dir  # Store the directory for the images\n\n            # Append to the full dataset\n            self.data = pd.concat([self.data, data_part_sampled], axis=0)\n\n        # Shuffle the dataset\n        self.data = self.data.sample(frac=1).reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Get the image name, handle cases with or without extension\n        img_name = self.data.iloc[idx]['name']\n        image_dir = self.data.iloc[idx]['image_dir']\n\n        # If the image name doesn't contain an extension, add one (e.g., '.png')\n#         if not any(ext in img_name for ext in ['.png', '.jpg','jpeg']):\n#             img_name = f\"{img_name}.png\"  # Default to .png, modify as per the image format you expect\n\n        img_path = os.path.join(image_dir, img_name)\n\n        try:\n            # Open the image and convert it to RGB\n            image = Image.open(img_path)\n        except Exception as e:\n            print(f\"Error loading image: {img_path}. Skipping to next image.\")\n            return self.__getitem__((idx + 1) % len(self.data))  # Skip to next image if an error occurs\n\n        # Get the label for the image\n        label = self.data.iloc[idx]['binary_label']\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:31:04.044935Z","iopub.execute_input":"2024-09-29T14:31:04.045579Z","iopub.status.idle":"2024-09-29T14:31:04.063Z","shell.execute_reply.started":"2024-09-29T14:31:04.045537Z","shell.execute_reply":"2024-09-29T14:31:04.062003Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"eyepacs_train=['/kaggle/input/eyepacs-ai4med/EyePACS/train','/kaggle/input/eyepacs-ai4med/EyePACS/train.csv']\neyepacs_test=['/kaggle/input/eyepacs-ai4med/EyePACS/test','/kaggle/input/eyepacs-ai4med/EyePACS/test.csv']\neyepacs_valid=['/kaggle/input/eyepacs-ai4med/EyePACS/valid','/kaggle/input/eyepacs-ai4med/EyePACS/valid.csv']\n\nidrid_train=['/kaggle/input/idrid-ai4med/idrid/train','/kaggle/input/idrid-ai4med/idrid/train.csv']\nidrid_test=['/kaggle/input/idrid-ai4med/idrid/test','/kaggle/input/idrid-ai4med/idrid/test.csv']\nidrid_valid=['/kaggle/input/idrid-ai4med/idrid/valid','/kaggle/input/idrid-ai4med/idrid/valid.csv']\n\nmessidor_train=['/kaggle/input/messidor-ai4med/train','/kaggle/input/messidor-ai4med/train.csv']\nmessidor_test=['/kaggle/input/messidor-ai4med/test','/kaggle/input/messidor-ai4med/test.csv']\nmessidor_valid=['/kaggle/input/messidor-ai4med/valid','/kaggle/input/messidor-ai4med/valid.csv']\n\naptos_train=['/kaggle/input/aptos2019/train_images/train_images','/kaggle/input/aptos2019/train_1.csv','id_code','diagnosis',False,'.png']\naptos_test=['/kaggle/input/aptos2019/test_images/test_images','/kaggle/input/aptos2019/test.csv','id_code','diagnosis',False,'.png']\naptos_valid=['/kaggle/input/aptos2019/val_images/val_images','/kaggle/input/aptos2019/valid.csv','id_code','diagnosis',False,'.png']\n\n\nhybrid_train=[eyepacs_train,idrid_train,messidor_train,aptos_train]\nhybrid_test=[eyepacs_test,idrid_test,messidor_test,aptos_test]\nhybrid_valid=[eyepacs_valid,idrid_valid,messidor_valid, aptos_valid]","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:30:59.827839Z","iopub.execute_input":"2024-09-29T14:30:59.828833Z","iopub.status.idle":"2024-09-29T14:30:59.837142Z","shell.execute_reply.started":"2024-09-29T14:30:59.828788Z","shell.execute_reply":"2024-09-29T14:30:59.836192Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## Train, Test and Validate Function","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nimport numpy as np\n\n# Training function\ndef train_model(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in tqdm(dataloader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Validation function\ndef validate_model(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n\n# Testing function\ndef test_model(model, dataloader, device):\n    model.eval()\n    all_labels = []\n    all_preds = []\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n    \n    return accuracy_score(all_labels, all_preds)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T12:02:51.106064Z","iopub.execute_input":"2024-09-29T12:02:51.106707Z","iopub.status.idle":"2024-09-29T12:03:00.004223Z","shell.execute_reply.started":"2024-09-29T12:02:51.106663Z","shell.execute_reply":"2024-09-29T12:03:00.003147Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Inception V3","metadata":{}},{"cell_type":"markdown","source":"Early Stopping and Learning Scheduler has been used here. It has three different functions for Training, Validating and Testing.","metadata":{}},{"cell_type":"code","source":"from torchvision.models import Inception_V3_Weights  \n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nimport numpy as np\n\n\n# Define image transformations\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\n# Parameters\nbatch_size = 32\nlearning_rate = 1e-4\n\n\n# Prepare dataset\n# train_image_dir = '/kaggle/input/hybrid-fundus-dataset/Train'\n# train_csv_file = '/kaggle/input/hybrid-fundus-dataset/train.csv'\n# train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=transform)\n\n# test_image_dir = '/kaggle/input/hybrid-fundus-dataset/Test'\n# test_csv_file = '/kaggle/input/hybrid-fundus-dataset/test.csv'\n# test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=transform,num_samples=100,nameColumn=\"Name\")\n\n# valid_image_dir = '/kaggle/input/hybrid-fundus-dataset/Valid'\n# valid_csv_file = '/kaggle/input/hybrid-fundus-dataset/valid.csv'\n# valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=transform,num_samples=100)\n\n\n# Create dataset instance\ntrain_dataset = MultiDatasetLoader(hybrid_train, transform=transform, num_samples=1000)\ntest_dataset = MultiDatasetLoader(hybrid_test, transform=transform, num_samples=1000)\nvalid_dataset = MultiDatasetLoader(hybrid_valid, transform=transform, num_samples=1000)\n\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# Load pre-trained InceptionV3 model\nmodel = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\nmodel.aux_logits = False\nmodel.fc = nn.Linear(model.fc.in_features, 2)\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T12:09:39.850584Z","iopub.execute_input":"2024-09-29T12:09:39.851401Z","iopub.status.idle":"2024-09-29T12:09:43.939318Z","shell.execute_reply.started":"2024-09-29T12:09:39.85136Z","shell.execute_reply":"2024-09-29T12:09:43.938306Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1000\n600\n172\n0\n300\n302\n0\n0\n600\n300\n13\n0\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n100%|██████████| 104M/104M [00:02<00:00, 37.9MB/s] \n","output_type":"stream"},{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 10\nbest_val_loss=np.inf\npatience=3\npatience_counter=0\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n\n# Training loop with early stopping\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n    scheduler.step()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n\n    # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Test the model\ntest_acc = test_model(model, test_loader, device)\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T12:10:23.660738Z","iopub.execute_input":"2024-09-29T12:10:23.661433Z","iopub.status.idle":"2024-09-29T12:27:26.881636Z","shell.execute_reply.started":"2024-09-29T12:10:23.661394Z","shell.execute_reply":"2024-09-29T12:27:26.880363Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 111/111 [02:03<00:00,  1.11s/it]\nValidation: 100%|██████████| 58/58 [00:54<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 0.3860, Train Accuracy: 0.8138\nValidation Loss: 0.3007, Validation Accuracy: 0.8724\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:51<00:00,  1.01s/it]\nValidation: 100%|██████████| 58/58 [00:49<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10\nTrain Loss: 0.2114, Train Accuracy: 0.9097\nValidation Loss: 0.3149, Validation Accuracy: 0.8664\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:51<00:00,  1.01s/it]\nValidation: 100%|██████████| 58/58 [00:50<00:00,  1.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10\nTrain Loss: 0.1396, Train Accuracy: 0.9438\nValidation Loss: 0.2976, Validation Accuracy: 0.8812\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:47<00:00,  1.03it/s]\nValidation: 100%|██████████| 58/58 [00:48<00:00,  1.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10\nTrain Loss: 0.0940, Train Accuracy: 0.9670\nValidation Loss: 0.4040, Validation Accuracy: 0.8916\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:48<00:00,  1.02it/s]\nValidation: 100%|██████████| 58/58 [00:48<00:00,  1.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10\nTrain Loss: 0.0693, Train Accuracy: 0.9760\nValidation Loss: 0.3540, Validation Accuracy: 0.8773\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:50<00:00,  1.01it/s]\nValidation: 100%|██████████| 58/58 [00:49<00:00,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10\nTrain Loss: 0.0521, Train Accuracy: 0.9817\nValidation Loss: 0.3325, Validation Accuracy: 0.8965\nEarly stopping triggered\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9252\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ResNet 50","metadata":{}},{"cell_type":"code","source":"from torchvision.models import ResNet50_Weights\nfrom torchvision.transforms import InterpolationMode\n\n# Define data transformations using ResNet18 inference transforms\nrestnet_preprocess = transforms.Compose([\n    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),  # Resizing to 256\n    transforms.CenterCrop(224),                                        # Central crop of 224\n    transforms.ToTensor(),                                             \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n])\nbatch_size=32\n# Prepare datasets\n# resnet_train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=restnet_preprocess)\n# resnet_test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=restnet_preprocess, num_samples=300,nameColumn=\"Name\")\n# resnet_valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=restnet_preprocess, num_samples=300)\nresnet_train_dataset = MultiDatasetLoader(hybrid_train, transform=restnet_preprocess, num_samples=1000)\nresnet_test_dataset = MultiDatasetLoader(hybrid_test, transform=restnet_preprocess, num_samples=1000)\nresnet_valid_dataset = MultiDatasetLoader(hybrid_valid, transform=restnet_preprocess, num_samples=1000)\n\n\n\n# Data loaders\nresnet_train_loader = DataLoader(resnet_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nresnet_val_loader = DataLoader(resnet_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\nresnet_test_loader = DataLoader(resnet_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n\nresnet_model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\nresnet_model.fc = nn.Linear(resnet_model.fc.in_features, 2)  # Adjust the final layer for binary classification\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nresnet_model.to(device)\nprint('')","metadata":{"execution":{"iopub.status.busy":"2024-09-29T12:27:26.88449Z","iopub.execute_input":"2024-09-29T12:27:26.88486Z","iopub.status.idle":"2024-09-29T12:27:28.349631Z","shell.execute_reply.started":"2024-09-29T12:27:26.88482Z","shell.execute_reply":"2024-09-29T12:27:28.348513Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1000\n600\n172\n0\n300\n302\n0\n0\n600\n300\n13\n0\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 178MB/s] \n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Define loss, optimizer, and learning rate scheduler\nresnet_criterion = nn.CrossEntropyLoss()\nresnet_optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\nresnet_scheduler = optim.lr_scheduler.StepLR(resnet_optimizer, step_size=5, gamma=0.1)\n\n# Early stopping setup\nbest_val_loss = float('inf')\npatience_counter = 0\npatience=3\nnum_epochs=10\n# Training loop with early stopping\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_model(resnet_model, resnet_train_loader, resnet_criterion, resnet_optimizer, device)\n    val_loss, val_acc = validate_model(resnet_model, resnet_val_loader, resnet_criterion, device)\n    resnet_scheduler.step()\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n    \n    # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Test the model\ntest_acc = test_model(resnet_model, resnet_test_loader, device)\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T12:27:28.351297Z","iopub.execute_input":"2024-09-29T12:27:28.351935Z","iopub.status.idle":"2024-09-29T12:46:03.726486Z","shell.execute_reply.started":"2024-09-29T12:27:28.351892Z","shell.execute_reply":"2024-09-29T12:46:03.725296Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:24<00:00,  1.32it/s]\nValidation: 100%|██████████| 58/58 [00:37<00:00,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 0.4847, Train Accuracy: 0.7689\nValidation Loss: 0.4475, Validation Accuracy: 0.7886\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:24<00:00,  1.32it/s]\nValidation: 100%|██████████| 58/58 [00:37<00:00,  1.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10\nTrain Loss: 0.3495, Train Accuracy: 0.8496\nValidation Loss: 0.4110, Validation Accuracy: 0.8182\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:23<00:00,  1.33it/s]\nValidation: 100%|██████████| 58/58 [00:36<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10\nTrain Loss: 0.2796, Train Accuracy: 0.8874\nValidation Loss: 0.3673, Validation Accuracy: 0.8390\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:23<00:00,  1.33it/s]\nValidation: 100%|██████████| 58/58 [00:36<00:00,  1.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10\nTrain Loss: 0.2507, Train Accuracy: 0.9024\nValidation Loss: 0.3822, Validation Accuracy: 0.8373\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:23<00:00,  1.33it/s]\nValidation: 100%|██████████| 58/58 [00:37<00:00,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10\nTrain Loss: 0.2191, Train Accuracy: 0.9125\nValidation Loss: 0.3730, Validation Accuracy: 0.8456\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:24<00:00,  1.32it/s]\nValidation: 100%|██████████| 58/58 [00:36<00:00,  1.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10\nTrain Loss: 0.1381, Train Accuracy: 0.9512\nValidation Loss: 0.3254, Validation Accuracy: 0.8680\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:23<00:00,  1.33it/s]\nValidation: 100%|██████████| 58/58 [00:36<00:00,  1.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10\nTrain Loss: 0.0891, Train Accuracy: 0.9676\nValidation Loss: 0.3437, Validation Accuracy: 0.8740\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:22<00:00,  1.34it/s]\nValidation: 100%|██████████| 58/58 [00:36<00:00,  1.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10\nTrain Loss: 0.0578, Train Accuracy: 0.9834\nValidation Loss: 0.3582, Validation Accuracy: 0.8724\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 111/111 [01:22<00:00,  1.35it/s]\nValidation: 100%|██████████| 58/58 [00:36<00:00,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10\nTrain Loss: 0.0318, Train Accuracy: 0.9924\nValidation Loss: 0.3983, Validation Accuracy: 0.8740\nEarly stopping triggered\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.9103\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## EfficientNet-B4","metadata":{}},{"cell_type":"code","source":"import torch\n# import torch_xla.core.xla_model as xm\nfrom torchvision.models import EfficientNet_B4_Weights\nfrom torchvision.transforms import InterpolationMode\n# Define EfficientNet-B7 inference preprocessing transforms\nefficientnet_preprocess = transforms.Compose([\n    transforms.Resize(384, interpolation=InterpolationMode.BICUBIC),  # Resize to 600 using BICUBIC interpolation\n    transforms.CenterCrop(380),                                        # Central crop of 600\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n])\n# train_image_dir = '/kaggle/input/aptos2019/train_images/train_images'\n# train_csv_file = '/kaggle/input/aptos2019/train_1.csv'\n# test_image_dir = '/kaggle/input/aptos2019/test_images/test_images'\n# test_csv_file = '/kaggle/input/aptos2019/test.csv'\n# valid_image_dir = '/kaggle/input/aptos2019/val_images/val_images'\n# valid_csv_file = '/kaggle/input/aptos2019/valid.csv'\n\n\n# Prepare datasets\n# efficientnet_train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=efficientnet_preprocess,num_samples=550)\n# efficientnet_valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=efficientnet_preprocess, num_samples=200)\n# efficientnet_test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=efficientnet_preprocess, num_samples=200,nameColumn=\"Name\")\nefficientnet_train_dataset = MultiDatasetLoader(hybrid_train, transform = efficientnet_preprocess, num_samples=1000)\nefficientnet_test_dataset = MultiDatasetLoader(hybrid_test, transform = efficientnet_preprocess, num_samples=1000)\nefficientnet_valid_dataset = MultiDatasetLoader(hybrid_valid, transform = efficientnet_preprocess, num_samples=1000)\n\n\n# Data loaders\nefficientnet_train_loader = DataLoader(efficientnet_train_dataset, batch_size=16, shuffle=True, num_workers=4)\nefficientnet_val_loader = DataLoader(efficientnet_valid_dataset, batch_size=16, shuffle=False, num_workers=4)\nefficientnet_test_loader = DataLoader(efficientnet_test_dataset, batch_size=16, shuffle=False, num_workers=4)\n\n# Initialize the EfficientNet-B7 model\n\nefficientnet_model = models.efficientnet_b4(weights=EfficientNet_B4_Weights.IMAGENET1K_V1)\nefficientnet_model.classifier[1] = nn.Linear(efficientnet_model.classifier[1].in_features, 2)  # Adjust final layer for binary classification\nefficientnet_model.to(device)\n\n# Define the loss, optimizer, and learning rate scheduler\nefficientnet_criterion = nn.CrossEntropyLoss()\nefficientnet_optimizer = optim.Adam(efficientnet_model.parameters(), lr=0.001)\nefficientnet_scheduler = optim.lr_scheduler.CosineAnnealingLR(efficientnet_optimizer, T_max=10)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:31:15.429607Z","iopub.execute_input":"2024-09-29T14:31:15.429999Z","iopub.status.idle":"2024-09-29T14:31:16.16382Z","shell.execute_reply.started":"2024-09-29T14:31:15.429962Z","shell.execute_reply":"2024-09-29T14:31:16.162843Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Class 0: 1000, Class 1: 1000\nClass 0: 600, Class 1: 600\nClass 0: 172, Class 1: 361\nClass 0: 1000, Class 1: 1000\nClass 0: 300, Class 1: 300\nClass 0: 305, Class 1: 302\nClass 0: 0, Class 1: 203\nClass 0: 229, Class 1: 137\nClass 0: 600, Class 1: 600\nClass 0: 300, Class 1: 300\nClass 0: 13, Class 1: 250\nClass 0: 212, Class 1: 154\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Early stopping setup\nbest_val_loss_efficientnet = float('inf')\npatience=3\n# Training loop for EfficientNet-B7 with early stopping\nnum_epoch=10\npatience_counter_efficientnet=0\nprint(\"Training EfficientNet-B7...\")\nfor epoch in range(num_epoch):\n    train_loss_efficientnet, train_acc_efficientnet = train_model(efficientnet_model, efficientnet_train_loader, efficientnet_criterion, efficientnet_optimizer, device)\n    val_loss_efficientnet, val_acc_efficientnet = validate_model(efficientnet_model, efficientnet_val_loader, efficientnet_criterion, device)\n    efficientnet_scheduler.step()\n\n    print(f\"EfficientNet-B7 Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss_efficientnet:.4f}, Train Accuracy: {train_acc_efficientnet:.4f}\")\n    print(f\"Validation Loss: {val_loss_efficientnet:.4f}, Validation Accuracy: {val_acc_efficientnet:.4f}\")\n\n    # Early stopping check\n    if val_loss_efficientnet < best_val_loss_efficientnet:\n        best_val_loss_efficientnet = val_loss_efficientnet\n        patience_counter_efficientnet = 0\n    else:\n        patience_counter_efficientnet += 1\n        if patience_counter_efficientnet >= patience:\n            print(\"Early stopping for EfficientNet-B7 triggered\")\n            break\n\n# Test the EfficientNet-B7 model\ntest_acc_efficientnet = test_model(efficientnet_model, efficientnet_test_loader, device)\nprint(f\"EfficientNet-B4 Test Accuracy: {test_acc_efficientnet:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ViT","metadata":{}},{"cell_type":"code","source":"from torchvision.models import ViT_B_32_Weights\nfrom torchvision import models, transforms\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n# Define data transformations using Vision Transformer inference transforms\nvit_preprocess = transforms.Compose([\n    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),  # Resize to 256\n    transforms.CenterCrop(224),                                        # Central crop of 224\n    transforms.ToTensor(),                                             \n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n])\nbatch_size=32\n\n# Prepare datasets\n# vit_train_dataset = BinaryClassificationDataset(image_dir=train_image_dir, csv_file=train_csv_file, transform=vit_preprocess)\n# vit_test_dataset = BinaryClassificationDataset(image_dir=test_image_dir, csv_file=test_csv_file, transform=vit_preprocess, num_samples=100,nameColumn=\"Name\")\n# vit_valid_dataset = BinaryClassificationDataset(image_dir=valid_image_dir, csv_file=valid_csv_file, transform=vit_preprocess, num_samples=100)\nvit_train_dataset = MultiDatasetLoader(hybrid_train, transform = vit_preprocess, num_samples=1000)\nvit_test_dataset = MultiDatasetLoader(hybrid_test, transform = vit_preprocess, num_samples=1000)\nvit_valid_dataset = MultiDatasetLoader(hybrid_valid, transform = vit_preprocess, num_samples=1000)\n\n# Data loaders\nvit_train_loader = DataLoader(vit_train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nvit_val_loader = DataLoader(vit_valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\nvit_test_loader = DataLoader(vit_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# Load pre-trained Vision Transformer (ViT-B/16) model\nvit_model = models.vit_b_32(weights=ViT_B_32_Weights.IMAGENET1K_V1)\nvit_model.heads.head = nn.Linear(vit_model.heads.head.in_features, 2)  # Adjust the final layer for binary classification\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:58:37.477266Z","iopub.execute_input":"2024-09-29T13:58:37.478155Z","iopub.status.idle":"2024-09-29T13:58:38.916231Z","shell.execute_reply.started":"2024-09-29T13:58:37.478112Z","shell.execute_reply":"2024-09-29T13:58:38.915379Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Class 0: 1000, Class 1: 1000\nClass 0: 600, Class 1: 600\nClass 0: 172, Class 1: 361\nClass 0: 300, Class 1: 300\nClass 0: 305, Class 1: 302\nClass 0: 0, Class 1: 203\nClass 0: 229, Class 1: 137\nClass 0: 600, Class 1: 600\nClass 0: 300, Class 1: 300\nClass 0: 13, Class 1: 250\nClass 0: 212, Class 1: 154\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvit_model.to(device)\n\n# Define loss, optimizer, and learning rate scheduler\nvit_criterion = nn.CrossEntropyLoss()\nvit_optimizer = optim.AdamW(vit_model.parameters(), lr=0.00005)\nvit_scheduler = optim.lr_scheduler.StepLR(vit_optimizer, step_size=5, gamma=0.1)\n\n# Early stopping setup\nbest_val_loss = float('inf')\npatience_counter = 0\npatience = 3\nnum_epochs = 20\n\n# Training loop with early stopping\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_model(vit_model, vit_train_loader, vit_criterion, vit_optimizer, device)\n    val_loss, val_acc = validate_model(vit_model, vit_val_loader, vit_criterion, device)\n    vit_scheduler.step()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n\n#     # Early stopping check\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(\"Early stopping triggered\")\n            break\n\n# Test the model\ntest_acc = test_model(vit_model, vit_test_loader, device)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Appendix\n","metadata":{}},{"cell_type":"code","source":"# Parameters\nimage_dir = '/kaggle/input/hybrid-fundus-dataset/Test'\ncsv_file = '/kaggle/input/hybrid-fundus-dataset/test.csv'\nn = 500  # Number of images per class\ntransform = transforms.Compose([\n    transforms.Resize((299, 299)),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Create dataset and dataloader\ndataset = BinaryClassificationDataset(image_dir=image_dir, csv_file=csv_file, transform=transform,nameColumn=\"Name\")\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n\n# Example usage: Iterating through the DataLoader\nfor images, labels in dataloader:\n    print(images.shape, labels.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-24T14:46:07.222204Z","iopub.status.idle":"2024-09-24T14:46:07.222677Z","shell.execute_reply.started":"2024-09-24T14:46:07.222458Z","shell.execute_reply":"2024-09-24T14:46:07.222492Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}